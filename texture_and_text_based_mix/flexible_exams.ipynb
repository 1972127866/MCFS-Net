{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/flexible_inference_texture_avg_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name red_yellow_blue_only_fine_mini_textures_for_test_1,7,8_sample_3,5,6,9 \\\n",
    "           -cloth_ids 3,5,6,9 \\\n",
    "           -texture_path ../editGANdata/mini_textures_for_test \\\n",
    "           -texture_ids 1,7,8 \\\n",
    "           -target_text red,yellow,blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/flexible_inference_texture_avg_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name textures_for_train_sample_0_10 \\\n",
    "           -cloth_ids 0-10 \\\n",
    "           -texture_path ../editGANdata/textures_for_train \\\n",
    "           -texture_ids 0-129 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.05it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:18<00:00, 21.96it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/deep_fashion_multi_model_texture_400\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_avg_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name deep_fashion_multi_model_texture_400 \\\n",
    "           -cloth_ids 0,7,8 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.62it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:13<00:00, 29.15it/s]\n",
      "len(delta_c_list): 300\n",
      "completedðŸ‘! Please check results in output/flexible/all_s_deep_fashion_multi_model_texture_300_400\n"
     ]
    }
   ],
   "source": [
    "# åœ¨620ä¸Šæµ‹è¯•deepfashion\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name all_s_deep_fashion_multi_model_texture_300_400 \\\n",
    "           -cloth_ids 0,7,8 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  5.25it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 470/470 [00:17<00:00, 27.55it/s]\n",
      "len(delta_c_list): 350\n",
      "generating result\n",
      "350it [00:30, 11.64it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/dtd_470_620t\n"
     ]
    }
   ],
   "source": [
    "# åœ¨620ä¸Šæµ‹è¯•dtd\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name dtd_470_620t \\\n",
    "           -cloth_ids 0-4 \\\n",
    "           -texture_path textures/dtd_470"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.39it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 156.75it/s]\n",
      "len(delta_c_list): 4\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "4it [00:00,  8.09it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/dtd_47_50_cids_1_pink_to_red_yellow_blue_green_black_white_purple_orange_gold_silver\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name dtd_47_50_cids_1_pink_to_red_yellow_blue_green_black_white_purple_orange_gold_silver \\\n",
    "           -cloth_ids 1 \\\n",
    "           -texture_ids 47-50 \\\n",
    "           -target_text red,yellow,blue,green,black,white,purple,orange,gold,silver  \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.45it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 151.78it/s]\n",
      "len(delta_c_list): 1\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "1it [00:00,  7.93it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/dtd_46_cids_1_pink_to_red_yellow_blue_green_black_white_purple_orange_gold_silver\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name dtd_46_cids_1_pink_to_red_yellow_blue_green_black_white_purple_orange_gold_silver \\\n",
    "           -cloth_ids 1 \\\n",
    "           -texture_ids 46 \\\n",
    "           -target_text red,yellow,blue,green,black,white,purple,orange,gold,silver  \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  6.65it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:05<00:00, 66.91it/s]\n",
      "len(delta_c_list): 100\n",
      "completedðŸ‘! Please check results in output/flexible/collar_all_s_deep_fashion_multi_model_texture_10_19\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name collar_all_s_deep_fashion_multi_model_texture_10_19 \\\n",
    "           -cloth_ids 10-19 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  \\\n",
    "            -sample_w_path ../editGANdata/collar_cloth_8385_300t_sample_200000/w \\\n",
    "            -stylegan_weights ../editGAN/collar_cloth_8385_300t.pt \\\n",
    "            -checkpoint_path checkpoints/all_s_extra_mapper_img_loss/resume/collar_cloth_8385_300t_sample_200000_all_s/texture_cropped_sample_200000_collar_cloth_8385_300t/net_640000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.75it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:17<00:00, 22.34it/s]\n",
      "len(delta_c_list): 300\n",
      "completedðŸ‘! Please check results in output/flexible/collar_all_s_deep_fashion_multi_model_texture_100_200\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name collar_all_s_deep_fashion_multi_model_texture_100_200 \\\n",
    "           -cloth_ids 1,2,11 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  \\\n",
    "            -sample_w_path ../editGANdata/collar_cloth_8385_300t_sample_200000/w \\\n",
    "            -stylegan_weights ../editGAN/collar_cloth_8385_300t.pt \\\n",
    "            -checkpoint_path checkpoints/all_s_extra_mapper_img_loss/resume/collar_cloth_8385_300t_sample_200000_all_s/texture_cropped_sample_200000_collar_cloth_8385_300t/net_640000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.80it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:17<00:00, 22.50it/s]\n",
      "len(delta_c_list): 300\n",
      "completedðŸ‘! Please check results in output/flexible/collar_all_s_deep_fashion_multi_model_texture_200_300\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name collar_all_s_deep_fashion_multi_model_texture_200_300 \\\n",
    "           -cloth_ids 1,2,11 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  \\\n",
    "            -sample_w_path ../editGANdata/collar_cloth_8385_300t_sample_200000/w \\\n",
    "            -stylegan_weights ../editGAN/collar_cloth_8385_300t.pt \\\n",
    "            -checkpoint_path checkpoints/all_s_extra_mapper_img_loss/resume/collar_cloth_8385_300t_sample_200000_all_s/texture_cropped_sample_200000_collar_cloth_8385_300t/net_640000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  3.71it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:20<00:00, 19.12it/s]\n",
      "len(delta_c_list): 400\n",
      "generating result\n",
      "400it [00:40,  9.95it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/collar_all_s_deep_fashion_multi_model_texture_256000pth_cloth0_3\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•åœ¨collaræ•°æ®é›†ä¸Šè®­ç»ƒäº†256000pthçš„æ¨¡åž‹\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name collar_all_s_deep_fashion_multi_model_texture_256000pth_cloth0_3 \\\n",
    "           -cloth_ids 0-3 \\\n",
    "           -texture_path ../editGANdata/deep_fashion_multi_model_texture_400  \\\n",
    "            -sample_w_path ../editGANdata/collar_cloth_8385_300t_sample_200000/w \\\n",
    "            -stylegan_weights ../editGAN/collar_cloth_8385_300t.pt \\\n",
    "            -checkpoint_path checkpoints/all_s_extra_mapper_img_loss/resume/collar_cloth_8385_300t_sample_200000_all_s/texture_cropped_sample_200000_collar_cloth_8385_300t/net_1280000.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:01<00:00,  8.85it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:02<00:00,  2.40it/s]\n",
      "len(delta_c_list): 60\n",
      "generating result\n",
      "60it [00:04, 12.86it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/good_texture_cids_52_98_118_224_232_822_847_882_897_1520\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name good_texture_cids_52_98_118_224_232_822_847_882_897_1520 \\\n",
    "           -cloth_ids 52,98,118,224,232,822,847,882,897,1520 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.32it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 42.52it/s]\n",
      "len(delta_c_list): 1\n",
      "generating result\n",
      "1it [00:00,  4.33it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/good_texture_0_cids_1520_pink_to_red_yellow_green_only_rgb\n"
     ]
    }
   ],
   "source": [
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name good_texture_0_cids_1520_pink_to_red_yellow_green_only_rgb \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -texture_ids 0 \\\n",
    "           -target_text red,yellow,green \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.29s/it]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 111.01it/s]\n",
      "len(delta_c_list): 1\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "1it [00:00, 15.39it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/good_texture_3_cids_1520_pink_to_green\n"
     ]
    }
   ],
   "source": [
    "#ç”Ÿæˆæ¡†æž¶å›¾ä¸Šçš„æ•ˆæžœå›¾ï¼ˆtexture+textï¼‰\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name good_texture_3_cids_1520_pink_to_green \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -texture_ids 3 \\\n",
    "           -target_text green \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.46it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 144.86it/s]\n",
      "len(delta_c_list): 1\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "1it [00:00, 57.78it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/good_texture_3_cids_1520\n"
     ]
    }
   ],
   "source": [
    "#ç”Ÿæˆæ¡†æž¶å›¾ä¸Šçš„æ•ˆæžœå›¾ï¼ˆonly textureï¼‰\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name good_texture_3_cids_1520 \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -texture_ids 3 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.58it/s]\n",
      "generating result\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 58.72it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_1520_pink_to_green\n"
     ]
    }
   ],
   "source": [
    "#ç”Ÿæˆæ¡†æž¶å›¾ä¸Šçš„æ•ˆæžœå›¾ï¼ˆonly textï¼‰\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_1520_pink_to_green \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -target_text green \\\n",
    "           -neutral pink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:01<00:00,  6.94it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:01<00:00,  3.53it/s]\n",
      "len(delta_c_list): 42\n",
      "generating result\n",
      "42it [00:03, 12.87it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/CGISF_texture_cids_0_974_1087_1235_1254_1668_1732\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•CGIFSä¸Šçš„çº¹ç†\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name CGISF_texture_cids_0_974_1087_1235_1254_1668_1732 \\\n",
    "           -cloth_ids 0,974,1087,1235,1254,1668,1732 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/CGISF_texture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:05<00:00, 19.21it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.26s/it]\n",
      "len(delta_c_list): 101\n",
      "generating result\n",
      "101it [00:07, 12.81it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/CGISF_texture_1_cids_0_100\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•CGIFSä¸Šçš„æ¡çº¹çº¹ç†\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name CGISF_texture_1_cids_0_100 \\\n",
    "           -cloth_ids 0-100 \\\n",
    "           -texture_ids 1 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/CGISF_texture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:03<00:00, 18.21it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.91s/it]\n",
      "len(delta_c_list): 70\n",
      "generating result\n",
      "70it [00:05, 12.85it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/MM23_texture_0_cids_81_150\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•MM2023è®ºæ–‡ä¸Šçš„çº¹ç†\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name MM23_texture_0_cids_81_150 \\\n",
    "           -cloth_ids 81-150 \\\n",
    "            -texture_ids 0 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/MM23_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.46it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:07<00:00,  4.10it/s]\n",
      "len(delta_c_list): 180\n",
      "generating result\n",
      "180it [00:14, 12.80it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/good_texture_cids_8_11_45_72_897_1254\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name good_texture_cids_8_11_45_72_897_1254 \\\n",
    "           -cloth_ids 8,11,45,72,897,1254 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00,  6.64it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:02<00:00,  4.06it/s]\n",
      "len(delta_c_list): 60\n",
      "generating result\n",
      "60it [00:04, 12.87it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/mini_textures_for_test_cids_8_11_45_72_897_1254\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name mini_textures_for_test_cids_8_11_45_72_897_1254 \\\n",
    "           -cloth_ids 8,11,45,72,897,1254 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/editGANdata/mini_textures_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.27it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:05<00:00, 78.68it/s]\n",
      "len(delta_c_list): 100\n",
      "generating result\n",
      "100it [00:09, 10.66it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/deep_fashion_cids_1\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name deep_fashion_cids_1 \\\n",
    "           -cloth_ids 1 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/editGANdata/deep_fashion_multi_model_texture_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.23it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:05<00:00, 78.54it/s]\n",
      "len(delta_c_list): 100\n",
      "generating result\n",
      "100it [00:09, 10.51it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/deep_fashion_cids_0_2\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆå®žéªŒç»“æžœå›¾\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name deep_fashion_cids_0_2 \\\n",
    "           -cloth_ids 2 \\\n",
    "           -texture_path /home/scut/workspace/wanqing/editGANdata/deep_fashion_multi_model_texture_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.33it/s]\n",
      "generating result\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.44it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_1520_pink_to_red_yellow_green\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_1520_pink_to_red_yellow_green \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -target_text red,yellow,green \\\n",
    "           -neutral pink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:01<00:00, 38.01it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:03<00:00, 15.38it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_0_50_plain_to_chequered_dotted_scaly_sprinkled_woven_braided\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_0_50_plain_to_chequered_dotted_scaly_sprinkled_woven_braided \\\n",
    "           -cloth_ids 0-50 \\\n",
    "           -target_text chequered,dotted,scaly,sprinkled,woven,braided \\\n",
    "           -neutral plain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:00<00:00, 74.31it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51/51 [00:02<00:00, 23.39it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_0_50_blank_to_plaid_printing_printed_striped\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_0_50_blank_to_plaid_printing_printed_striped \\\n",
    "           -cloth_ids 0-50 \\\n",
    "           -target_text plaid,printing,printed,striped \\\n",
    "           -neutral blank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.97it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 36.16it/s]\n",
      "len(delta_c_list): 4\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "4it [00:00, 24.98it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_22_good_texture_42_45_plain_to_wrinkled_striped\n"
     ]
    }
   ],
   "source": [
    "# çº¹ç†æŽ§é¢œè‰²ï¼Œæ–‡æœ¬æŽ§å›¾æ¡ˆ\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_texture_for_color.py \\\n",
    "           -save_name cids_22_good_texture_42_45_plain_to_wrinkled_striped \\\n",
    "           -cloth_ids 22 \\\n",
    "           -target_text wrinkled,striped \\\n",
    "           -texture_id 42-45 \\\n",
    "           -neutral plain \\\n",
    "            -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.39it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 156.16it/s]\n",
      "len(delta_c_list): 4\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "4it [00:00, 64.16it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_22_good_texture_51_54_plain_to_plaid\n"
     ]
    }
   ],
   "source": [
    "# çº¹ç†æŽ§é¢œè‰²ï¼Œæ–‡æœ¬æŽ§å›¾æ¡ˆ\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_texture_for_color.py \\\n",
    "           -save_name cids_22_good_texture_51_54_plain_to_plaid \\\n",
    "           -cloth_ids 22 \\\n",
    "           -target_text plaid \\\n",
    "           -texture_id 51-54 \\\n",
    "           -neutral plain \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.36it/s]\n",
      "generating result\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "dt.shape: torch.Size([512])\n",
      "delta_c_text[0, 512:].shape: torch.Size([512])\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.60it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_1520_flat_to_stripe_polka_dot_floral_velour_camouflage\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_1520_flat_to_stripe_polka_dot_floral_velour_camouflage \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -target_text stripe,polka_dot,floral,velour,camouflage \\\n",
    "           -neutral flat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.43it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.67it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_1520_plain_fabric_to_stripe_polka_dot_floral_velour_camouflage\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_1520_plain_fabric_to_stripe_polka_dot_floral_velour_camouflage \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -target_text stripe,polka_dot,floral,velour,camouflage \\\n",
    "           -neutral plain_fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.36it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_628_blue_to_red_yellow_green_only_rgb\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_628_blue_to_red_yellow_green_only_rgb \\\n",
    "           -cloth_ids 628 \\\n",
    "           -target_text red,yellow,green \\\n",
    "           -neutral pink "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.27it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.53it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_8_plain_fabric_to_stripe_velour_camouflage_plaid_tartan_check\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_8_plain_fabric_to_stripe_velour_camouflage_plaid_tartan_check \\\n",
    "           -cloth_ids 8 \\\n",
    "           -target_text stripe,polka_dot,floral,velour,camouflage,plaid,tartan,check \\\n",
    "           -neutral plain_fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.68it/s]\n",
      "generating result\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.50it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_13_15_plain_fabric_to_tartan_plaid\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ› æ ¼çº¹\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_13_15_plain_fabric_to_tartan_plaid \\\n",
    "           -cloth_ids 13-15 \\\n",
    "           -target_text plaid,tartan \\\n",
    "           -neutral plain_fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py\", line 188, in <module>\n",
      "    main(opt)\n",
      "  File \"scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py\", line 68, in main\n",
      "    net = net.to(device)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 612, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 381, in _apply\n",
      "    param_applied = fn(param)\n",
      "  File \"/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 610, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 23.70 GiB total capacity; 613.53 MiB already allocated; 8.69 MiB free; 672.00 MiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬ç¼–è¾‘èƒ½åŠ› æ¡çº¹\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss_only_text.py \\\n",
    "           -save_name cids_13_plain_fabric_to_striped_vertical_striped \\\n",
    "           -cloth_ids 13 \\\n",
    "           -target_text striped,vertical_striped \\\n",
    "           -neutral plain_fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.92it/s]\n",
      "Loading all textures in folder\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 400/400 [00:01<00:00, 234.31it/s]\n",
      "len(delta_c_list): 100\n",
      "generating result\n",
      "100it [00:11,  8.59it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_1520_deep_fashion_multi_model_texture_0_100_pink_to_red_orange_yellow_green_blue\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬+çº¹ç†ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name cids_1520_deep_fashion_multi_model_texture_0_100_pink_to_red_orange_yellow_green_blue \\\n",
    "           -cloth_ids 1520 \\\n",
    "           -target_text  red,orange,yellow,green,blue\\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/editGANdata/deep_fashion_multi_model_texture_400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  6.16it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 65.23it/s]\n",
      "len(delta_c_list): 6\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "6it [00:00, 26.13it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_7_1520_good_texture_30_36_pink_to_red_yellow_green\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬+çº¹ç†ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name cids_7_1520_good_texture_30_33_34_pink_to_red_yellow_green \\\n",
    "           -cloth_ids 7,1520 \\\n",
    "           -target_text  blue\\\n",
    "           -texture_id 30,33,34 \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "sampling cloths\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  3.63it/s]\n",
      "Loading specified texture\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 54.28it/s]\n",
      "len(delta_c_list): 6\n",
      "generating result\n",
      "0it [00:00, ?it/s]/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  arr = np.asanyarray(arr)\n",
      "/home/scut/workspace/anaconda3/envs/deltaEdit/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n",
      "6it [00:00, 17.53it/s]\n",
      "completedðŸ‘! Please check results in output/flexible/cids_7_1520_good_texture_30_33_46_pink_to_red_blue_green\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æ–‡æœ¬+çº¹ç†ç¼–è¾‘èƒ½åŠ›\n",
    "!python scripts/flexible_inference_texture_all_s_extra_mapper_img_loss.py \\\n",
    "           -save_name cids_7_1520_good_texture_30_33_46_pink_to_red_blue_green \\\n",
    "           -cloth_ids 7,1520 \\\n",
    "           -target_text  red,blue,green\\\n",
    "           -texture_id 30,33,46 \\\n",
    "           -neutral pink \\\n",
    "           -texture_path /home/scut/workspace/wanqing/DeltaEdit-main/textures/good_texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 3/6 [00:00<00:00, 17.59it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ       | 5/6 [00:00<00:00, 14.91it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 12.61it/s]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 4/6 [00:00<00:00, 39.54it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 40.59it/s]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ               | 4/6 [00:00<00:00, 35.32it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 34.56it/s]\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 3/6 [00:00<00:00, 25.45it/s]256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "256 256\n",
      "(256, 256, 3)\n",
      "(258, 258)\n",
      "sketch_mask.shape (256, 256)\n",
      "orig_mask.shape (256, 256)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:00<00:00, 23.08it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:01<00:00,  2.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é£Žæ ¼æ··åˆ\n",
    "!python scripts/mix_fm.py  -source_pic_ids 5003-5006 -targets 1007,1008,1014,1006,1032,1043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 57.39it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é£Žæ ¼æ··åˆ\n",
    "!python scripts/mix_fm.py  -source_pic_ids 5011 -targets 1007,1008,1014,1006,1032,1043,1018,1010,1040,1044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.34it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•é£Žæ ¼æ··åˆ\n",
    "!python scripts/mix_fm.py  -source_pic_ids 5011 -targets 1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stylegan weights from pretrained!\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 36.14it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 56.91it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 58.61it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  6.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# æ¡†æž¶å›¾ç¤ºä¾‹å›¾é£Žæ ¼æ··åˆ\n",
    "!python scripts/mix_fm.py  -source_pic_ids 5012-5014 -targets 1007 -th 150"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
