{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ecd4f85-161a-4a2e-b76d-14e5c387191f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'editGAN'\n",
      "/home/scut/wuwanqing/editGAN\n"
     ]
    }
   ],
   "source": [
    "cd editGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224b8d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826aeefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "python train_encoder.py --exp experiments/encoder_car.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf70da12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6223c310-ca93-4851-b2b2-4032142252fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"create_pics.py\", line 139, in <module>\r\n",
      "    creatPics(opt)\r\n",
      "  File \"create_pics.py\", line 65, in creatPics\r\n",
      "    G = legacy.load_network_pkl(f)['G_ema'].to(device)\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 673, in to\r\n",
      "    return self._apply(convert)\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 387, in _apply\r\n",
      "    module._apply(fn)\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 387, in _apply\r\n",
      "    module._apply(fn)\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 387, in _apply\r\n",
      "    module._apply(fn)\r\n",
      "  [Previous line repeated 1 more time]\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 409, in _apply\r\n",
      "    param_applied = fn(param)\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 671, in convert\r\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\r\n",
      "RuntimeError: CUDA error: out of memory\r\n"
     ]
    }
   ],
   "source": [
    "!python create_pics.py -pic_num=1 -sema_inx=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934437bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python create_pics_min.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9a58ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/500 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████| 500/500 [03:06<00:00,  2.69it/s]\n"
     ]
    }
   ],
   "source": [
    "!python heatMapMean.py -pic_num=500 -sema_inx=4 -special_channel=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22aefcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████| 200/200 [00:16<00:00, 11.86it/s]\n"
     ]
    }
   ],
   "source": [
    "!python create_pic_plus.py -pic_num=200 -sema_inx=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8814bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  4.13it/s]\n"
     ]
    }
   ],
   "source": [
    "!python create_pic_plus_sample.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "947150b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "All files,  5\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Curr dir, lanbo\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../hdd/wanqing/editGAN/sketch_embed/w-step600_s-step500\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/sketch/tmp/lanbo.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "before_w_optied,p_loss: tensor(0.2995, device='cuda:0') ,mse_loss: tensor(0.0203, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 599/599 [01:26<00:00,  6.94it/s]\n",
      "loss: tensor(1.3388, device='cuda:0', grad_fn=<AddBackward0>)   reconstruction_loss: tensor(1.1344, device='cuda:0', grad_fn=<AddBackward0>)   encoder_loss: tensor(0.2045, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Curr loss,  3.0157406330108643 1.1343512535095215\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.08 loss 0.08 \n",
      "Elapsed: 28.1 s\n",
      " 20%|████████▊                                   | 1/5 [01:54<07:39, 114.95s/it]Curr dir, 1126\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../hdd/wanqing/editGAN/sketch_embed/w-step600_s-step500\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/sketch/tmp/1126.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3587, device='cuda:0') ,mse_loss: tensor(0.0150, device='cuda:0')\n",
      " 67%|███████████████████████████▎             | 399/599 [00:57<00:28,  6.92it/s]\n",
      "loss: tensor(2.0373, device='cuda:0', grad_fn=<AddBackward0>)   reconstruction_loss: tensor(1.8713, device='cuda:0', grad_fn=<AddBackward0>)   encoder_loss: tensor(0.1661, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Curr loss,  3.602306365966797 1.8712552785873413\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.14 loss 0.14 \n",
      "Elapsed: 28.0 s\n",
      " 40%|██████████████████                           | 2/5 [03:21<04:53, 97.96s/it]Curr dir, huachenshan\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../hdd/wanqing/editGAN/sketch_embed/w-step600_s-step500\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/sketch/tmp/huachenshan.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.4156, device='cuda:0') ,mse_loss: tensor(0.0579, device='cuda:0')\n",
      " 60%|████████████████████████▍                | 357/599 [00:51<00:34,  6.92it/s]\n",
      "loss: tensor(3.4020, device='cuda:0', grad_fn=<AddBackward0>)   reconstruction_loss: tensor(3.2099, device='cuda:0', grad_fn=<AddBackward0>)   encoder_loss: tensor(0.1921, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Curr loss,  4.214099884033203 3.2099037170410156\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.18 loss 0.18 \n",
      "Elapsed: 28.0 s\n",
      " 60%|███████████████████████████                  | 3/5 [04:41<02:59, 89.77s/it]Curr dir, lanchen1\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../hdd/wanqing/editGAN/sketch_embed/w-step600_s-step500\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/sketch/tmp/lanchen1.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3635, device='cuda:0') ,mse_loss: tensor(0.0138, device='cuda:0')\n",
      " 78%|████████████████████████████████         | 469/599 [01:07<00:18,  6.92it/s]\n",
      "loss: tensor(2.2421, device='cuda:0', grad_fn=<AddBackward0>)   reconstruction_loss: tensor(1.9507, device='cuda:0', grad_fn=<AddBackward0>)   encoder_loss: tensor(0.2914, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Curr loss,  3.6488685607910156 1.9506934881210327\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.10 loss 0.10 \n",
      "Elapsed: 28.0 s\n",
      " 80%|████████████████████████████████████         | 4/5 [06:17<01:32, 92.27s/it]Curr dir, lanchen\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../hdd/wanqing/editGAN/sketch_embed/w-step600_s-step500\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/sketch/tmp/lanchen.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3720, device='cuda:0') ,mse_loss: tensor(0.0109, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 599/599 [01:26<00:00,  6.94it/s]\n",
      "loss: tensor(1.8650, device='cuda:0', grad_fn=<AddBackward0>)   reconstruction_loss: tensor(1.5923, device='cuda:0', grad_fn=<AddBackward0>)   encoder_loss: tensor(0.2727, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Curr loss,  3.730578899383545 1.5922722816467285\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.11 loss 0.11 \n",
      "Elapsed: 28.0 s\n",
      "100%|█████████████████████████████████████████████| 5/5 [08:11<00:00, 98.36s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed-project.py --steps=600 --num_steps=500 --exp experiments/encoder_cloth.json --resume ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada/checkpoint/BEST_loss2.5923986434936523.pth --testing_path ../../hdd/wanqing/editGAN/sketch/tmp --latent_sv_folder ../../hdd/wanqing/editGAN/sketch_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a5f0af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Using cached charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/scut/anaconda3/envs/editGAN2/lib/python3.8/site-packages (from requests) (2022.9.24)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, requests\n",
      "Successfully installed charset-normalizer-2.1.1 idna-3.4 requests-2.28.1 urllib3-1.26.12\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d030d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading networks...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                  | 0/5000 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|███████████████████████████████████████| 5000/5000 [02:13<00:00, 37.51it/s]\n"
     ]
    }
   ],
   "source": [
    "!python sample_pics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5733e14-64d6-4470-af0e-356692e906c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [14, 15, 16, 17, 18, 19]\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 14.20it/s]\n"
     ]
    }
   ],
   "source": [
    "!python stylemix.py -latents_path='../../hdd/wanqing/editGAN/latent_S'  -source_pic_id=1116 -targets=241 -styles=14-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d96d383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 30.17it/s]\n"
     ]
    }
   ],
   "source": [
    "!python stylemix.py -latents_path='../../hdd/wanqing/editGAN/latent_S' -sample_pic=True -source_pic_id=1944 -targets=6,7,9 -styles=7-19 -output_path='../../workspace/wanqing/editGANresult/rebuttal/stylemix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9393cb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "source from sample\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 60.80it/s]\n"
     ]
    }
   ],
   "source": [
    "!python stylemix_test.py -latents_path='../../hdd/wanqing/editGAN/latent_S' -sample_pic=True -source_pic_id=3715 -targets=241 -styles=0-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c37257aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "inputs[0][0][0] tensor(0.9909, device='cuda:0')\n",
      "inputs[0][0][0] tensor(0.9909, device='cuda:0')\n",
      "inputshape[0][0][0] tensor(1., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41a241d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  5.79it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  6.42it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:00<00:00,  6.53it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:02<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "!python fm_mix.py -sample_pic=True -th=150 -source_pic_ids=650,2457,558 -targets=1007,1006,1040,1018 -res_mix=128 -styles=7-19 -use_sketch=True -output_path='../../hdd/wanqing/editGAN/paper_result_pic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da534d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 17.72it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 21.92it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 21.45it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 21.30it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 33.09it/s]\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.09it/s]\n"
     ]
    }
   ],
   "source": [
    "!python fm_mix.py  -sample_pic=True -th=220 -source_pic_ids=1063,6343,5801,882,1712  -targets=1007 -res_mix=64 -styles=7-19 -use_sketch=True -output_path='../../workspace/wanqing/editGANresult/rebuttal/fm_mix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cac40d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 18.13it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 33.18it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 30.68it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.00it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 31.13it/s]\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "!python fm_mix.py  -sample_pic=True -th=220 -source_pic_ids=1063,6343,5801,882,1712  -targets=1007 -res_mix=64 -styles=7-19 -use_sketch=True -output_path='../../workspace/wanqing/editGANresult/rebuttal/fm_mix_wo stylemix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9001d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fm_mix.py  -sample_pic=True -th=220 -source_pic_ids=1063,6343,5801,882,1712  -targets=1003 -res_mix=64 -styles=7-19 -use_sketch=True -output_path='/home/scut/workspace/wanqing/editGANresult/rebuttal/fm_mix_wo_stylemix_2024'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b9dca37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 44.24it/s]\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "sketch_mask [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "orig_mask [[55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " ...\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]\n",
      " [55 55 55 ... 55 55 55]]\n",
      "mix_pic.shape torch.Size([1, 3, 256, 256])\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00, 46.36it/s]\n",
      "100%|█████████████████████████████████████████████| 2/2 [00:00<00:00,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "!python fm_mix.py  -th=220 \\\n",
    "    -source_pic_ids=5003-5004  -targets=1003,1007,1008 \\\n",
    "        -res_mix=64 -styles=7-19 -use_sketch=True \\\n",
    "            -output_path='/home/scut/workspace/wanqing/editGANresult/fm_mix_stylemix_deltaEdit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a960b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a154aa69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "styles [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 29.74it/s]\n"
     ]
    }
   ],
   "source": [
    "!python stylemix.py -latents_path='/home/scut/hdd/wanqing/editGAN/latent_S'  -sample_target=True -source_pic_id=1007 -targets=1063,6343,5801,882,1712 -styles=7-19 -output_path='/home/scut/workspace/wanqing/editGANresult/rebuttal/stylemix_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab235a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 23 14:57:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.108.03   Driver Version: 510.108.03   CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 31%   46C    P8    33W / 350W |      1MiB / 24576MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d64e577",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43658dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (4.6.0.66)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.1/108.1 kB\u001b[0m \u001b[31m646.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (0.19.3)\n",
      "Requirement already satisfied: click in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from opencv-python) (1.23.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (9.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (2.8.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (1.8.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (2.19.5)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from scikit-image) (2022.5.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (3.0.9)\n",
      "Installing collected packages: ninja\n",
      "Successfully installed ninja-1.10.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python ninja scikit-image click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888b5b62-27e6-48b0-bbd8-ce7886b8f4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\r\n",
      "Copyright (c) 2005-2020 NVIDIA Corporation\r\n",
      "Built on Mon_Oct_12_20:09:46_PDT_2020\r\n",
      "Cuda compilation tools, release 11.1, V11.1.105\r\n",
      "Build cuda_11.1.TC455_06.29190527_0\r\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afad8446-3cde-47f0-9f7e-5c6c6970b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.7.1+cu110 in /root/miniconda3/lib/python3.8/site-packages (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision==0.8.2+cu110 in /root/miniconda3/lib/python3.8/site-packages (0.8.2+cu110)\n",
      "Requirement already satisfied: torchaudio===0.7.2 in /root/miniconda3/lib/python3.8/site-packages (0.7.2)\n",
      "Requirement already satisfied: typing-extensions in /root/miniconda3/lib/python3.8/site-packages (from torch==1.7.1+cu110) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/lib/python3.8/site-packages (from torch==1.7.1+cu110) (1.21.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /root/miniconda3/lib/python3.8/site-packages (from torchvision==0.8.2+cu110) (8.3.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3ec7358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting Flask==2.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/54/4f/1b294c1a4ab7b2ad5ca5fc4a9a65a22ef1ac48be126289d97668852d4ab3/Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m936.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Flask_Cors==3.0.10\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
      "Collecting imageio==2.15.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/49/f9/4986d7ea281875be92f7780b1d77c1e2e1d1b8f6669c9bb784065c7777cc/imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ipdb==0.13.9\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fc/56/9f67dcd4a4b9960373173a31be1b8c47fe351a1c9385677a7bdd82810e57/ipdb-0.13.9.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ipython==8.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ef/88/3e505ba3accd31f464f92dcd8c229f2d0d7af14ead91c1899c52648336be/ipython-8.0.1-py3-none-any.whl (747 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m747.5/747.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy==1.21.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/aa/69/260a4a1cc89cc00b51f432db048c396952f5c05dfa1345a1b3dbd9ea3544/numpy-1.21.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting Pillow==9.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/7f/58f056f31358956f8aaaf042982693d96f3d35d5a9df94acecdabb1db6f8/Pillow-9.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting scikit_image==0.15.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e0/46/ca035f5d7d3414124a3a5ef22cd2e75c0c5149042a668375f1d44eb69f8f/scikit-image-0.15.0.tar.gz (32.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.3/32.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy==1.6.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/16/48/5deccafd975b8f63f6e32b585835035c6806fca0cef3c4d45e4489f251cc/scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.2/27.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting skimage==0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3b/ee/edbfa69ba7b7d9726e634bfbeefd04b5a1764e9e74867ec916113eeaf4a1/skimage-0.0.tar.gz (757 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[3 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m *** Please install the `scikit-image` package (instead of `skimage`) ***\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3c44f6fd51c57b371a4bd12fb9c82d953425d826598731921ab119afb0baaa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
