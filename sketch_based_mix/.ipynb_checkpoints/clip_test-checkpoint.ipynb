{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute_preservation_lambda': 1.0,\n",
      " 'background_lambda': 1.0,\n",
      " 'batch_size': 1,\n",
      " 'board_interval': 50,\n",
      " 'both_manipulation_prob': 0.27,\n",
      " 'checkpoint_path': None,\n",
      " 'color_description': 'purple, red, orange, yellow, green, blue, gray, brown, '\n",
      "                      'black, white, blond, pink',\n",
      " 'color_in_domain_ref_manipulation_prob': 0.25,\n",
      " 'color_manipulation_prob': 0.2,\n",
      " 'color_ref_img_in_domain_path': '../data/gen_color',\n",
      " 'color_ref_img_test_path': '../data/afhq/val',\n",
      " 'color_ref_img_train_path': '../data/afhq/train',\n",
      " 'color_text_manipulation_prob': 0.5,\n",
      " 'exp_dir': '../experiment/hairtest',\n",
      " 'hairstyle_description': 'hairstyle_list.txt',\n",
      " 'hairstyle_manipulation_prob': 0.5,\n",
      " 'hairstyle_ref_img_test_path': '../data/afhq/val',\n",
      " 'hairstyle_ref_img_train_path': '../data/afhq/train',\n",
      " 'hairstyle_text_manipulation_prob': 0.5,\n",
      " 'id_lambda': 0.3,\n",
      " 'image_color_lambda': 0.02,\n",
      " 'image_hairstyle_lambda': 5.0,\n",
      " 'image_interval': 100,\n",
      " 'image_manipulation_lambda': 1.0,\n",
      " 'ir_se50_weights': '../pretrained_models/model_ir_se50.pth',\n",
      " 'latent_l2_lambda': 0.8,\n",
      " 'latents_test_path': '../pretrained_models/test_faces.pt',\n",
      " 'latents_train_path': '../pretrained_models/train_faces.pt',\n",
      " 'learning_rate': 0.0005,\n",
      " 'maintain_color_lambda': 0.02,\n",
      " 'max_steps': 500000,\n",
      " 'no_coarse_mapper': False,\n",
      " 'no_fine_mapper': False,\n",
      " 'no_medium_mapper': False,\n",
      " 'num_for_each_augmented_color': 4000,\n",
      " 'optim_name': 'ranger',\n",
      " 'parsenet_weights': '../pretrained_models/parsenet.pth',\n",
      " 'save_interval': 2000,\n",
      " 'stylegan_size': 1024,\n",
      " 'stylegan_weights': '../pretrained_models/stylegan2-ffhq-config-f.pt',\n",
      " 'test_batch_size': 1,\n",
      " 'test_dataset_size': 1000,\n",
      " 'test_workers': 2,\n",
      " 'text_manipulation_lambda': 2.0,\n",
      " 'train_dataset_size': 5000,\n",
      " 'val_interval': 2000,\n",
      " 'workers': 4}\n",
      "Loading decoder weights from pretrained!\n",
      "Loading ResNet ArcFace for ID Loss\n",
      "Loading UNet for Background Loss\n",
      "Loading UNet for AvgLabLoss\n",
      "Loading UNet for AvgLabLoss\n",
      "Number of training samples: 24176\n",
      "Number of test samples: 2824\n",
      "Traceback (most recent call last):\n",
      "  File \"scripts/train.py\", line 34, in <module>\n",
      "    main(opts)\n",
      "  File \"scripts/train.py\", line 27, in main\n",
      "    coach.train()\n",
      "  File \"/home/scut/workspace/wanqing/HairCLIP-main/mapper/../mapper/training/coach.py\", line 92, in train\n",
      "    x_hat, w_hat = self.net.decoder([w_hat], input_is_latent=True, return_latents=True, randomize_noise=False, truncation=1)\n",
      "  File \"/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/scut/workspace/wanqing/HairCLIP-main/mapper/../models/stylegan2/model.py\", line 531, in forward\n",
      "    out = conv2(out, latent[:, i + 1], noise=noise2)\n",
      "  File \"/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/scut/workspace/wanqing/HairCLIP-main/mapper/../models/stylegan2/model.py\", line 336, in forward\n",
      "    out = self.activate(out)\n",
      "  File \"/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/scut/workspace/wanqing/HairCLIP-main/mapper/../models/stylegan2/op/fused_act.py\", line 20, in forward\n",
      "    return fused_leaky_relu(input, self.bias, self.negative_slope, self.scale)\n",
      "  File \"/home/scut/workspace/wanqing/HairCLIP-main/mapper/../models/stylegan2/op/fused_act.py\", line 35, in fused_leaky_relu\n",
      "    F.leaky_relu(\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.68 GiB total capacity; 3.06 GiB already allocated; 68.19 MiB free; 3.25 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "#hairclip的训练代码\n",
    "\n",
    "!python scripts/train.py --exp_dir ../experiment/hairtest \\\n",
    "        --hairstyle_description=\"hairstyle_list.txt\" \\\n",
    "        --color_description=\"purple, red, orange, yellow, green, blue, gray, brown, black, white, blond, pink\" \\\n",
    "        --latents_train_path=../pretrained_models/train_faces.pt \\\n",
    "        --latents_test_path=../pretrained_models/test_faces.pt \\\n",
    "        --hairstyle_ref_img_train_path=../data/afhq/train \\\n",
    "        --hairstyle_ref_img_test_path=../data/afhq/val \\\n",
    "        --color_ref_img_train_path=../data/afhq/train \\\n",
    "        --color_ref_img_test_path=../data/afhq/val \\\n",
    "        --color_ref_img_in_domain_path=../data/gen_color \\\n",
    "        --hairstyle_manipulation_prob=0.5 \\\n",
    "        --color_manipulation_prob=0.2 \\\n",
    "        --both_manipulation_prob=0.27 \\\n",
    "        --hairstyle_text_manipulation_prob=0.5 \\\n",
    "        --color_text_manipulation_prob=0.5 \\\n",
    "        --color_in_domain_ref_manipulation_prob=0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"mapper/train.py\", line 13, in <module>\r\n",
      "    from mapper.coach import Coach\r\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/./mapper/coach.py\", line 2, in <module>\r\n",
      "    import clip\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/clip-1.0-py3.8.egg/clip/__init__.py\", line 1, in <module>\r\n",
      "    from .clip import *\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/clip-1.0-py3.8.egg/clip/clip.py\", line 8, in <module>\r\n",
      "    import torch\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/__init__.py\", line 617, in <module>\r\n",
      "    import torch.hub\r\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/hub.py\", line 16, in <module>\r\n",
      "    from tqdm.auto import tqdm  # automatically select proper tqdm submodule if available\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 839, in exec_module\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 934, in get_code\r\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_data\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python mapper/train.py --exp_dir ../editGANresult/clipMapper_result \\\n",
    "        --hairstyle_description=../mapper/description/cloth_description.txt \\\n",
    "        --color_description=\"purple, red, orange, yellow, green, blue, gray, brown, black, white, blond, pink\" \\\n",
    "        --clothstyle_manipulation_prob=1 \\\n",
    "        --color_manipulation_prob=0 \\\n",
    "        --both_manipulation_prob=0 \\\n",
    "        --clothstyle_text_manipulation_prob=1 \\\n",
    "        --color_text_manipulation_prob=0 \\\n",
    "        --stylegan_checkpoint_path=cloth-v2-620t-s-test.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-sxdwfxo6\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-sxdwfxo6\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from checkpoint: ../pretrained_models/best_model.pt\n",
      "Loading UNet for AvgLabLoss\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      " 17%|███████▌                                     | 1/6 [00:04<00:24,  4.98s/it]/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      " 33%|███████████████                              | 2/6 [00:05<00:09,  2.44s/it]/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      " 50%|██████████████████████▌                      | 3/6 [00:06<00:04,  1.62s/it]/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      " 67%|██████████████████████████████               | 4/6 [00:06<00:02,  1.23s/it]/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [00:07<00:01,  1.02s/it]/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "/home/scut/anaconda3/envs/hairCLIP/lib/python3.8/site-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
      "  warnings.warn(warning)\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:08<00:00,  1.37s/it]\n"
     ]
    }
   ],
   "source": [
    "#hairclip的测试代码\n",
    "\n",
    "!python scripts/inference.py --end_index=6\\\n",
    "--exp_dir=../experiment/collar_test \\\n",
    "--checkpoint_path=../pretrained_models/best_model.pt \\\n",
    "--latents_test_path=../pretrained_models/test_latents.pt \\\n",
    "--editing_type=hairstyle \\\n",
    "--input_type=text \\\n",
    "--hairstyle_description=\"collarstyle_list.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd02e5b91674361d466e549e836fcde1002a257b42dc1f94b151ad98257279ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
