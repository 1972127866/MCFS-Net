{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/workspace/wanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "All files,  100\n",
      "  0%|                                                   | 0/100 [00:00<?, ?it/s]Curr dir, test_085\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: /home/scut/workspace/wanqing/editGANresult/embed_wo_noise_term/fashionTOP_testset100/w-step400_s-step250\n",
      "****** Run optimization for  /home/scut/workspace/wanqing/editGANdata/fashionTOP_testset100/test_085.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      " 65%|██████████████████████████▊              | 261/399 [00:45<00:23,  5.87it/s]"
     ]
    }
   ],
   "source": [
    "!python embed-project_wo_noise_term.py --steps=400 --num_steps=250 --exp experiments/encoder_cloth.json \\\n",
    "    --resume /home/scut/hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada/checkpoint/BEST_loss2.5923986434936523.pth \\\n",
    "    --testing_path /home/scut/workspace/wanqing/editGANdata/fashionTOP_testset100 \\\n",
    "    --latent_sv_folder /home/scut/workspace/wanqing/editGANresult/embed_wo_noise_term/fashionTOP_testset100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
