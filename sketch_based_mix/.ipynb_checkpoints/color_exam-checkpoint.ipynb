{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "All files,  1\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Curr dir, 3\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/localedit-color_embed/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/localedit-color/3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "before_w_optied,p_loss: tensor(0.3815, device='cuda:0') ,mse_loss: tensor(0.0199, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:56<00:00,  7.00it/s]\n",
      "Curr loss,  3.8346292972564697 0.9747360348701477\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:57<00:00, 57.54s/it]\n"
     ]
    }
   ],
   "source": [
    "#以下几个为对基于restyle的嵌入方法进行消融\n",
    "!python embed_project_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth.json --resume ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada/checkpoint/BEST_loss2.5923986434936523.pth --testing_path ../../workspace/wanqing/editGANdata/localedit-color --latent_sv_folder ../../workspace/wanqing/editGANresult/localedit-color_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../../workspace/wanqing/editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\n",
      "Loading decoder weights from pretrained path: cloth-v2-620t-s-test.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  6\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Curr dir, 10\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/10.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.4436, device='cuda:0') ,mse_loss: tensor(0.0121, device='cuda:0')\n",
      " 68%|███████████████████████████▊             | 271/399 [00:09<00:04, 28.18it/s]\n",
      "Curr loss,  4.448627948760986 3.5313243865966797\n",
      " 17%|███████▌                                     | 1/6 [00:10<00:51, 10.35s/it]Curr dir, 11\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/11.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.2122, device='cuda:0') ,mse_loss: tensor(0.0137, device='cuda:0')\n",
      " 55%|██████████████████████▌                  | 219/399 [00:06<00:05, 31.76it/s]\n",
      "Curr loss,  2.1356067657470703 1.3094526529312134\n",
      " 33%|███████████████                              | 2/6 [00:17<00:34,  8.74s/it]Curr dir, 6\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/6.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.2630, device='cuda:0') ,mse_loss: tensor(0.0078, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:14<00:00, 27.72it/s]\n",
      "Curr loss,  2.6378443241119385 1.074913740158081\n",
      " 50%|██████████████████████▌                      | 3/6 [00:33<00:34, 11.64s/it]Curr dir, 8\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/8.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.2916, device='cuda:0') ,mse_loss: tensor(0.0136, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:15<00:00, 25.62it/s]\n",
      "Curr loss,  2.9298832416534424 1.4654308557510376\n",
      " 67%|██████████████████████████████               | 4/6 [00:49<00:26, 13.44s/it]Curr dir, 3\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3150, device='cuda:0') ,mse_loss: tensor(0.0069, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:16<00:00, 24.92it/s]\n",
      "Curr loss,  3.156994581222534 1.2085330486297607\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [01:05<00:14, 14.61s/it]Curr dir, 9\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/9.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3336, device='cuda:0') ,mse_loss: tensor(0.0132, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.72it/s]\n",
      "Curr loss,  3.348806619644165 2.125684976577759\n",
      "100%|█████████████████████████████████████████████| 6/6 [01:19<00:00, 13.33s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed_project_restyle_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth.json --resume ../../workspace/wanqing/editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt --testing_path ../../workspace/wanqing/editGANdata/cloth_for_test_restyle --latent_sv_folder ../../workspace/wanqing/editGANresult/exam_for_restyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "All files,  6\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Curr dir, 10\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/10.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "before_w_optied,p_loss: tensor(0.5371, device='cuda:0') ,mse_loss: tensor(0.0164, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.14it/s]\n",
      "Curr loss,  5.387051582336426 3.265995502471924\n",
      " 17%|███████▌                                     | 1/6 [00:32<02:41, 32.38s/it]Curr dir, 11\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/11.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3530, device='cuda:0') ,mse_loss: tensor(0.0469, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.19it/s]\n",
      "Curr loss,  3.5766854286193848 1.1092097759246826\n",
      " 33%|███████████████                              | 2/6 [01:03<02:06, 31.55s/it]Curr dir, 6\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/6.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.2959, device='cuda:0') ,mse_loss: tensor(0.0282, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.15it/s]\n",
      "Curr loss,  2.987036943435669 0.858929455280304\n",
      " 50%|██████████████████████▌                      | 3/6 [01:34<01:33, 31.31s/it]Curr dir, 8\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/8.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3356, device='cuda:0') ,mse_loss: tensor(0.0491, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.17it/s]\n",
      "Curr loss,  3.405064344406128 1.4337908029556274\n",
      " 67%|██████████████████████████████               | 4/6 [02:05<01:02, 31.19s/it]Curr dir, 3\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3779, device='cuda:0') ,mse_loss: tensor(0.0200, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.16it/s]\n",
      "Curr loss,  3.799445867538452 0.918770968914032\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [02:36<00:31, 31.12s/it]Curr dir, 9\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/9.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.4228, device='cuda:0') ,mse_loss: tensor(0.1670, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.15it/s]\n",
      "Curr loss,  4.395234107971191 1.9772876501083374\n",
      "100%|█████████████████████████████████████████████| 6/6 [03:07<00:00, 31.24s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed_project_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth.json --resume ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada/checkpoint/BEST_loss2.5923986434936523.pth --testing_path ../../workspace/wanqing/editGANdata/cloth_for_test_restyle --latent_sv_folder ../../workspace/wanqing/editGANresult/exam_for_restyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../../workspace/wanqing/editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\n",
      "Loading decoder weights from pretrained path: cloth-v2-620t-s-test.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  6\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Curr dir, 10\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/10.jpg  ******\n",
      "before_w_optied,p_loss: tensor(0.4424, device='cuda:0') ,mse_loss: tensor(0.0119, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.24it/s]\n",
      "Curr loss,  4.435904026031494 3.5611572265625\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.27 loss 0.54 \n",
      "Elapsed: 6.1 s\n",
      " 17%|███████▌                                     | 1/6 [00:09<00:49,  9.86s/it]Curr dir, 11\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/11.jpg  ******\n",
      "before_w_optied,p_loss: tensor(0.2169, device='cuda:0') ,mse_loss: tensor(0.0135, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.70it/s]\n",
      "Curr loss,  2.182386875152588 1.3291423320770264\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.09 loss 0.73 \n",
      "Elapsed: 4.7 s\n",
      " 33%|███████████████                              | 2/6 [00:18<00:36,  9.02s/it]Curr dir, 6\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/6.png  ******\n",
      "before_w_optied,p_loss: tensor(0.2660, device='cuda:0') ,mse_loss: tensor(0.0077, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.81it/s]\n",
      "Curr loss,  2.6680238246917725 1.1892963647842407\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.07 loss 1.13 \n",
      "Elapsed: 4.7 s\n",
      " 50%|██████████████████████▌                      | 3/6 [00:26<00:26,  8.74s/it]Curr dir, 8\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/8.jpg  ******\n",
      "before_w_optied,p_loss: tensor(0.2880, device='cuda:0') ,mse_loss: tensor(0.0132, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.66it/s]\n",
      "Curr loss,  2.892904281616211 1.71782648563385\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.12 loss 0.74 \n",
      "Elapsed: 4.7 s\n",
      " 67%|██████████████████████████████               | 4/6 [00:35<00:17,  8.61s/it]Curr dir, 3\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/3.jpg  ******\n",
      "before_w_optied,p_loss: tensor(0.3104, device='cuda:0') ,mse_loss: tensor(0.0068, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.70it/s]\n",
      "Curr loss,  3.110398530960083 1.4147096872329712\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.09 loss 1.67 \n",
      "Elapsed: 4.7 s\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [00:43<00:08,  8.54s/it]Curr dir, 9\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/9.png  ******\n",
      "before_w_optied,p_loss: tensor(0.3382, device='cuda:0') ,mse_loss: tensor(0.0134, device='cuda:0')\n",
      "100%|███████████████████████████████████████████| 99/99 [00:02<00:00, 33.58it/s]\n",
      "Curr loss,  3.3958935737609863 2.33198881149292\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "dist 0.17 loss 0.82 \n",
      "Elapsed: 4.8 s\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:51<00:00,  8.67s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed_project_restyle.py --steps=100 --num_steps=100 --exp experiments/encoder_cloth.json --resume ../../workspace/wanqing/editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt --testing_path ../../workspace/wanqing/editGANdata/cloth_for_test_restyle --latent_sv_folder ../../workspace/wanqing/editGANresult/exam_for_restyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/wuwanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "All files,  6\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Curr dir, 10\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/10.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "before_w_optied,p_loss: tensor(0.5371, device='cuda:0') ,mse_loss: tensor(0.0164, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.12it/s]\n",
      "Curr loss,  5.386917591094971 3.273096799850464\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.23 loss 0.23 \n",
      "Elapsed: 12.2 s\n",
      " 17%|███████▌                                     | 1/6 [00:44<03:43, 44.66s/it]Curr dir, 11\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/11.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3542, device='cuda:0') ,mse_loss: tensor(0.0468, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.13it/s]\n",
      "Curr loss,  3.5890040397644043 1.1529520750045776\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.08 loss 0.08 \n",
      "Elapsed: 9.3 s\n",
      " 33%|███████████████                              | 2/6 [01:25<02:48, 42.17s/it]Curr dir, 6\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/6.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.2989, device='cuda:0') ,mse_loss: tensor(0.0282, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.07it/s]\n",
      "Curr loss,  3.0169565677642822 0.8722093105316162\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.06 loss 0.06 \n",
      "Elapsed: 8.8 s\n",
      " 50%|██████████████████████▌                      | 3/6 [02:05<02:03, 41.15s/it]Curr dir, 8\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/8.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3353, device='cuda:0') ,mse_loss: tensor(0.0490, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 12.97it/s]\n",
      "Curr loss,  3.402409553527832 1.3798738718032837\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.09 loss 0.10 \n",
      "Elapsed: 12.2 s\n",
      " 67%|██████████████████████████████               | 4/6 [02:48<01:24, 42.16s/it]Curr dir, 3\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.3759, device='cuda:0') ,mse_loss: tensor(0.0200, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.06it/s]\n",
      "Curr loss,  3.7790071964263916 0.9968001246452332\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.06 loss 0.06 \n",
      "Elapsed: 8.9 s\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [03:28<00:41, 41.43s/it]Curr dir, 9\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "SV folder at: ../../workspace/wanqing/editGANresult/exam_for_restyle/w-step400_s-step250\n",
      "****** Run optimization for  ../../workspace/wanqing/editGANdata/cloth_for_test_restyle/9.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "before_w_optied,p_loss: tensor(0.4248, device='cuda:0') ,mse_loss: tensor(0.1673, device='cuda:0')\n",
      "100%|█████████████████████████████████████████| 399/399 [00:30<00:00, 13.02it/s]\n",
      "Curr loss,  4.415045738220215 1.9519761800765991\n",
      "Computing W midpoint and stddev using 100 samples...\n",
      "dist 0.13 loss 0.14 \n",
      "Elapsed: 8.7 s\n",
      "100%|█████████████████████████████████████████████| 6/6 [04:08<00:00, 41.50s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed-project.py --steps=400 --num_steps=250 --exp experiments/encoder_cloth.json --resume ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada/checkpoint/BEST_loss2.5923986434936523.pth --testing_path ../../workspace/wanqing/editGANdata/cloth_for_test_restyle --latent_sv_folder ../../workspace/wanqing/editGANresult/exam_for_restyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/workspace/wanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\n",
      "Loading decoder weights from pretrained path: cloth-v2-620t-s-test.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  20\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]Curr dir, edge_tex_1_0\n",
      "****** Run optimization for  ../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada  ******\n",
      "inputs.shape torch.Size([1, 3, 256, 256])\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step100_s-step100\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample_0_4/edge_tex_1_0.jpg  ******\n",
      "100%|███████████████████████████████████████████| 99/99 [00:03<00:00, 31.04it/s]\n",
      "Curr loss,  4.662998199462891 3.1748344898223877\n",
      "Computing S midpoint and stddev using 100 samples...\n",
      "  0%|                                                    | 0/20 [00:03<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"embed_project_restyle.py\", line 466, in <module>\n",
      "    test_stylegan_proj(opts, args.resume, args.steps,num_steps=args.num_steps,\n",
      "  File \"embed_project_restyle.py\", line 373, in test_stylegan_proj\n",
      "    projected_w_steps = project(\n",
      "  File \"embed_project_restyle.py\", line 123, in project\n",
      "    _, _, s_samples = G.module.synthesis(w_samples, noise_mode='const', return_style=True)\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<string>\", line 527, in forward\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<string>\", line 435, in forward\n",
      "  File \"/home/scut/anaconda3/envs/editGAN/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 889, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<string>\", line 303, in forward\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/torch_utils/misc.py\", line 101, in decorator\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"<string>\", line 66, in modulated_conv2d\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/torch_utils/misc.py\", line 101, in decorator\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/torch_utils/ops/conv2d_resample.py\", line 138, in conv2d_resample\n",
      "    x = _conv2d_wrapper(x=x, w=w, stride=up, padding=[pyt,pxt], groups=groups, transpose=True, flip_weight=(not flip_weight))\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/torch_utils/ops/conv2d_resample.py\", line 54, in _conv2d_wrapper\n",
      "    return op(x, w, stride=stride, padding=padding, groups=groups)\n",
      "  File \"/home/scut/workspace/wanqing/editGAN/torch_utils/ops/conv2d_gradfix.py\", line 43, in conv_transpose2d\n",
      "    return torch.nn.functional.conv_transpose2d(input=input, weight=weight, bias=bias, stride=stride, padding=padding, output_padding=output_padding, groups=groups, dilation=dilation)\n",
      "RuntimeError: CUDA out of memory. Tried to allocate 808.00 MiB (GPU 0; 23.70 GiB total capacity; 2.88 GiB already allocated; 687.69 MiB free; 3.82 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "#嵌入轮廓图和带纹理的轮廓图 到620t的潜空间 记得检查psp.py里载入的styleGAN模型是不是对应的\n",
    "!python embed_project_restyle.py --steps=100 --num_steps=100 --exp experiments/encoder_cloth_360t.json \\\n",
    "    --testing_path ../editGANdata/textures_with_edge_620t_sample_0_4 \\\n",
    "    --latent_sv_folder ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/workspace/wanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\n",
      "Loading decoder weights from pretrained path: cloth-v2-620t-s-test.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  20\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]Curr dir, edge_tex_1_0\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_1_0.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.49it/s]\n",
      "Curr loss,  4.746142864227295 3.1410951614379883\n",
      "  5%|██▏                                         | 1/20 [00:13<04:15, 13.42s/it]Curr dir, edge_0\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_0.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.47it/s]\n",
      "Curr loss,  3.0288476943969727 0.6749618053436279\n",
      " 10%|████▍                                       | 2/20 [00:26<04:01, 13.41s/it]Curr dir, edge_tex_0_1\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_0_1.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 28.65it/s]\n",
      "Curr loss,  4.050498962402344 1.9937794208526611\n",
      " 15%|██████▌                                     | 3/20 [00:41<03:54, 13.79s/it]Curr dir, edge_tex_2_0\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_2_0.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:14<00:00, 28.17it/s]\n",
      "Curr loss,  4.219959735870361 2.565495491027832\n",
      " 20%|████████▊                                   | 4/20 [00:55<03:44, 14.06s/it]Curr dir, edge_tex_1_3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_1_3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.07it/s]\n",
      "Curr loss,  3.89461612701416 1.9729557037353516\n",
      " 25%|███████████                                 | 5/20 [01:09<03:28, 13.89s/it]Curr dir, edge_tex_1_2\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_1_2.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.21it/s]\n",
      "Curr loss,  3.9103646278381348 2.2087554931640625\n",
      " 30%|█████████████▏                              | 6/20 [01:22<03:12, 13.76s/it]Curr dir, edge_tex_2_2\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_2_2.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:14<00:00, 27.79it/s]\n",
      "Curr loss,  3.376098394393921 1.7346824407577515\n",
      " 35%|███████████████▍                            | 7/20 [01:37<03:02, 14.06s/it]Curr dir, edge_tex_3_1\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_3_1.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:14<00:00, 27.89it/s]\n",
      "Curr loss,  5.281281471252441 2.3578007221221924\n",
      " 40%|█████████████████▌                          | 8/20 [01:51<02:50, 14.24s/it]Curr dir, edge_tex_3_2\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_3_2.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.50it/s]\n",
      "Curr loss,  4.2018537521362305 2.342101812362671\n",
      " 45%|███████████████████▊                        | 9/20 [02:05<02:35, 14.12s/it]Curr dir, edge_tex_0_0\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_0_0.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.68it/s]\n",
      "Curr loss,  4.245449542999268 2.5932374000549316\n",
      " 50%|█████████████████████▌                     | 10/20 [02:19<02:20, 14.01s/it]Curr dir, edge_3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 28.98it/s]\n",
      "Curr loss,  3.8659167289733887 0.713912844657898\n",
      " 55%|███████████████████████▋                   | 11/20 [02:33<02:06, 14.03s/it]Curr dir, edge_tex_0_3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_0_3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 28.77it/s]\n",
      "Curr loss,  3.300175428390503 1.6560813188552856\n",
      " 60%|█████████████████████████▊                 | 12/20 [02:47<01:52, 14.08s/it]Curr dir, edge_tex_1_1\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_1_1.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.91it/s]\n",
      "Curr loss,  4.722771167755127 2.1272239685058594\n",
      " 65%|███████████████████████████▉               | 13/20 [03:01<01:37, 13.95s/it]Curr dir, edge_tex_2_1\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_2_1.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.20it/s]\n",
      "Curr loss,  4.497076511383057 1.7460695505142212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 14/20 [03:15<01:22, 13.82s/it]Curr dir, edge_1\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_1.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.41it/s]\n",
      "Curr loss,  3.9964494705200195 0.8543444275856018\n",
      " 75%|████████████████████████████████▎          | 15/20 [03:28<01:09, 13.84s/it]Curr dir, edge_tex_3_0\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_3_0.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.20it/s]\n",
      "Curr loss,  5.178055286407471 3.374250650405884\n",
      " 80%|██████████████████████████████████▍        | 16/20 [03:42<00:54, 13.75s/it]Curr dir, edge_2\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_2.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.61it/s]\n",
      "Curr loss,  3.8998186588287354 0.6591103672981262\n",
      " 85%|████████████████████████████████████▌      | 17/20 [03:56<00:41, 13.76s/it]Curr dir, edge_tex_2_3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_2_3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.23it/s]\n",
      "Curr loss,  3.373978853225708 1.3781869411468506\n",
      " 90%|██████████████████████████████████████▋    | 18/20 [04:09<00:27, 13.69s/it]Curr dir, edge_tex_3_3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_3_3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.27it/s]\n",
      "Curr loss,  4.288093566894531 1.9651598930358887\n",
      " 95%|████████████████████████████████████████▊  | 19/20 [04:23<00:13, 13.63s/it]Curr dir, edge_tex_0_2\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/textures_with_edge_620t_sample0_4_bold/edge_tex_0_2.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.43it/s]\n",
      "Curr loss,  3.3363099098205566 1.9603418111801147\n",
      "100%|███████████████████████████████████████████| 20/20 [04:37<00:00, 13.86s/it]\n"
     ]
    }
   ],
   "source": [
    "#嵌入轮廓图和带纹理的轮廓图 到620t的潜空间 不经过s空间的优化 记得检查psp.py里载入的styleGAN模型是不是对应的\n",
    "!python embed_project_restyle_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth.json  \\\n",
    "    --testing_path ../editGANdata/textures_with_edge_620t_sample0_4 \\\n",
    "    --latent_sv_folder ../editGANresult/restyleEmbedResult/textures_with_edge_620t_sample_0_4_restyle\\\n",
    "    --checkpoint_path ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\\\n",
    "    --resume ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'cloth-v2-620t-s-test.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '../data/cloth', 'label_data_path': '', 'testing_data_path': '', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"cloth-v2-620t-s-test.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/workspace/wanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\n",
      "Loading decoder weights from pretrained path: cloth-v2-620t-s-test.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  6\n",
      "  0%|                                                     | 0/6 [00:00<?, ?it/s]Curr dir, 10\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/10.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.60it/s]\n",
      "Curr loss,  4.396446704864502 3.040947437286377\n",
      " 17%|███████▌                                     | 1/6 [00:13<01:06, 13.39s/it]Curr dir, 11\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/11.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.55it/s]\n",
      "Curr loss,  2.1855716705322266 1.0897186994552612\n",
      " 33%|███████████████                              | 2/6 [00:26<00:53, 13.39s/it]Curr dir, 6\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/6.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.25it/s]\n",
      "Curr loss,  2.6690735816955566 0.938069760799408\n",
      " 50%|██████████████████████▌                      | 3/6 [00:40<00:40, 13.65s/it]Curr dir, 8\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/8.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.36it/s]\n",
      "Curr loss,  2.869478940963745 1.4209264516830444\n",
      " 67%|██████████████████████████████               | 4/6 [00:54<00:27, 13.58s/it]Curr dir, 3\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/3.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 30.38it/s]\n",
      "Curr loss,  3.1357643604278564 1.11104416847229\n",
      " 83%|█████████████████████████████████████▌       | 5/6 [01:07<00:13, 13.53s/it]Curr dir, 9\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/cloth_for_test_restyle/9.png  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      "100%|█████████████████████████████████████████| 399/399 [00:13<00:00, 29.50it/s]\n",
      "Curr loss,  3.405377149581909 2.033421754837036\n",
      "100%|█████████████████████████████████████████████| 6/6 [01:21<00:00, 13.58s/it]\n"
     ]
    }
   ],
   "source": [
    "!python embed_project_restyle_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth.json  \\\n",
    "    --testing_path ../editGANdata/cloth_for_test_restyle \\\n",
    "    --latent_sv_folder ../editGANresult/restyleEmbedResult/cloth_for_test_restyle_restyle\\\n",
    "    --checkpoint_path ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt\\\n",
    "    --resume ../editGANdata/restyle_encoder_psp_fashionTop_110000/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000000000cuda_home: /usr/local/cuda-11.1\n",
      "Opt {'exp_dir': '../../hdd/wanqing/editGAN/model_encoder/cloth_batch_8_loss_sampling_train_stylegan2ada', 'category': 'car', 'im_size': [256, 256], 'n_latent': 14, 'lr': 3e-05, 'debug': False, 'bs': 8, 'sample_bs': 2, 'avg_latent': '', 'stylegan_checkpoint': 'viton_360t_s_fm.pkl', 'max_label': 7, 'classfier_checkpoint': '', 'training_data_path': '', 'label_data_path': '', 'testing_data_path': '../editGANdata/textures_with_edge_620t_sample_0_4', 'sampling_training': True, 'use_w': False, 'same_view_code': False, 'truncation': False, 'normalize': True, 'stylegan_ver': '3', 'train_real_start_epochs': 5, 'dim': 4992, 'loss_dict': {'p_loss': 10, 'mse_loss': 1, 'encoder_loss': 5, 'e_label_ce_loss': 1, 'e_label_dice_loss': 1}, 'use_noise': False, 'noise_loss_weight': 100}\n",
      "Loading networks from \"viton_360t_s_fm.pkl\"...\n",
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      " make_mean_latent \n",
      "Setting up Perceptual loss...\n",
      "Loading model from: /home/scut/workspace/wanqing/editGAN/lpips/weights/v0.1/vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n",
      "Loading ReStyle pSp from checkpoint: ../editGANdata/restyle_encoder_psp_viton_180000/best_model.pt\n",
      "Loading decoder weights from pretrained path:viton_360t_s_fm.pkl\n",
      " make_mean_latent \n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "All files,  20\n",
      "  0%|                                                    | 0/20 [00:00<?, ?it/s]Curr dir, 9\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/texture_and_edge/edges_for_train_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/texture_and_edge/edges_for_train/9.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      " 86%|███████████████████████████████████▎     | 344/399 [00:09<00:01, 36.93it/s]\n",
      "Curr loss,  2.5887537002563477 0.7957313656806946\n",
      "  5%|██▏                                         | 1/20 [00:09<03:02,  9.62s/it]Curr dir, 44\n",
      "SV folder at: ../editGANresult/restyleEmbedResult/texture_and_edge/edges_for_train_restyle/w-step400_s-step0\n",
      "****** Run optimization for  ../editGANdata/texture_and_edge/edges_for_train/44.jpg  ******\n",
      "latent_in.shape torch.Size([1, 14, 512])\n",
      " 12%|█████                                     | 48/399 [00:01<00:09, 37.22it/s]"
     ]
    }
   ],
   "source": [
    "#嵌入轮廓图和带纹理的轮廓图 到360t的潜空间 不经过s空间的优化 记得检查psp.py里载入的styleGAN模型是不是对应的\n",
    "!python embed_project_restyle_wo_s.py --steps=400 --num_steps=0 --exp experiments/encoder_cloth_360t.json  \\\n",
    "    --testing_path ../editGANdata/texture_and_edge/edges_for_train \\\n",
    "    --latent_sv_folder ../editGANresult/restyleEmbedResult/texture_and_edge/edges_for_train_restyle\\\n",
    "    --checkpoint_path ../editGANdata/restyle_encoder_psp_viton_180000/best_model.pt\\\n",
    "    --resume ../editGANdata/restyle_encoder_psp_viton_180000/best_model.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3c44f6fd51c57b371a4bd12fb9c82d953425d826598731921ab119afb0baaa3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
